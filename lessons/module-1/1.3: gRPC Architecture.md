# 1.3: gRPC Architecture

## ğŸ—ï¸ The Big Picture: How gRPC Works

gRPC is like a sophisticated postal system for your applications. Let's break down how messages travel from client to server and back.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    HTTP/2     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚ â•â•â•â•â•â•â•â•â•â•â•>  â”‚   Server    â”‚
â”‚             â”‚   Protocol    â”‚             â”‚
â”‚  [Stub]     â”‚   Buffers     â”‚ [Service]   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ <â•â•â•â•â•â•â•â•â•â•â•â• â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### The Journey of a gRPC Call

1. **Client** creates a request using generated stub
2. **Protocol Buffers** serialize the data to binary
3. **HTTP/2** transports the binary data efficiently
4. **Server** receives and deserializes the request
5. **Service** processes the request and creates response
6. **Response travels back** through the same pipeline

---

## ğŸŒ HTTP/2: The Foundation

gRPC builds on HTTP/2, which gives us superpowers compared to traditional HTTP/1.1:

### HTTP/1.1 vs HTTP/2 Comparison

| Feature | HTTP/1.1 | HTTP/2 |
|---------|-----------|---------|
| **Connections** | One request per connection | Multiple requests per connection |
| **Header Compression** | âŒ None | âœ… HPACK compression |
| **Server Push** | âŒ Not supported | âœ… Server can push data |
| **Binary Protocol** | âŒ Text-based | âœ… Binary framing |
| **Stream Multiplexing** | âŒ Head-of-line blocking | âœ… Concurrent streams |

### Real-World Impact

**Traditional REST API (HTTP/1.1):**
```
Client opens connection 1 â†’ GET /users/123
Client opens connection 2 â†’ GET /users/123/orders  
Client opens connection 3 â†’ GET /users/123/profile
```

**gRPC with HTTP/2:**
```
Client opens 1 connection:
  Stream 1 â†’ GetUser(123)
  Stream 3 â†’ GetUserOrders(123)  
  Stream 5 â†’ GetUserProfile(123)
All streams run concurrently! ğŸš€
```

---

## ğŸ­ The Four Types of gRPC Services

Let's define different communication patterns using our e-commerce example:

### 1. Unary RPC (Request-Response)
*One request, one response - like a simple function call*

```protobuf
service UserService {
  // Get a single user by ID
  rpc GetUser(GetUserRequest) returns (User);
  
  // Create a new user
  rpc CreateUser(CreateUserRequest) returns (User);
}

message GetUserRequest {
  int32 user_id = 1;
}

message CreateUserRequest {
  string email = 1;
  string first_name = 2;
  string last_name = 3;
}
```

**Use Cases:** CRUD operations, authentication, simple queries

### 2. Server Streaming RPC
*One request, multiple responses - like subscribing to updates*

```protobuf
service OrderService {
  // Get real-time order status updates
  rpc StreamOrderUpdates(OrderUpdatesRequest) returns (stream OrderUpdate);
  
  // Get all user orders (paginated via streaming)
  rpc GetUserOrders(GetUserOrdersRequest) returns (stream Order);
}

message OrderUpdatesRequest {
  int32 order_id = 1;
}

message OrderUpdate {
  int32 order_id = 1;
  OrderStatus status = 2;
  string message = 3;
  int64 timestamp = 4;
}
```

**Use Cases:** Real-time notifications, live dashboards, large data sets

### 3. Client Streaming RPC
*Multiple requests, one response - like uploading chunks*

```protobuf
service FileService {
  // Upload a large file in chunks
  rpc UploadFile(stream FileChunk) returns (UploadResponse);
  
  // Batch create multiple products
  rpc BatchCreateProducts(stream CreateProductRequest) returns (BatchCreateResponse);
}

message FileChunk {
  string filename = 1;
  bytes data = 2;
  bool is_last_chunk = 3;
}

message UploadResponse {
  string file_url = 1;
  int64 file_size = 2;
  string checksum = 3;
}
```

**Use Cases:** File uploads, batch operations, telemetry data

### 4. Bidirectional Streaming RPC
*Multiple requests, multiple responses - like a conversation*

```protobuf
service ChatService {
  // Real-time chat between users
  rpc Chat(stream ChatMessage) returns (stream ChatMessage);
  
  // Live collaboration on documents
  rpc CollaborateDocument(stream DocumentEdit) returns (stream DocumentUpdate);
}

message ChatMessage {
  int32 user_id = 1;
  string message = 2;
  int64 timestamp = 3;
  int32 room_id = 4;
}

message DocumentEdit {
  string document_id = 1;
  int32 user_id = 2;
  string operation = 3;  // "insert", "delete", "format"
  string content = 4;
  int32 position = 5;
}
```

**Use Cases:** Chat applications, real-time collaboration, gaming

---

## ğŸ”Œ Channels: The Connection Highway

A **Channel** represents a connection to a gRPC server. Think of it as a highway between your client and server.

### Channel Lifecycle

```javascript
// 1. Create Channel
const grpc = require('@grpc/grpc-js');
const channel = new grpc.Channel(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

// 2. Channel States
// IDLE â†’ CONNECTING â†’ READY â†’ TRANSIENT_FAILURE â†’ SHUTDOWN

// 3. Check channel state
console.log('Channel state:', channel.getConnectivityState());

// 4. Wait for connection
channel.watchConnectivityState(
  grpc.connectivityState.CONNECTING,
  Date.now() + 5000,
  (error) => {
    if (error) {
      console.log('Failed to connect');
    } else {
      console.log('Connected!');
    }
  }
);

// 5. Close channel when done
channel.close();
```

### Channel Configuration Options

```javascript
const channel = new grpc.Channel('localhost:50051', 
  grpc.credentials.createInsecure(),
  {
    // Connection settings
    'grpc.keepalive_time_ms': 10000,           // Send keepalive every 10s
    'grpc.keepalive_timeout_ms': 2000,         // Wait 2s for keepalive response
    'grpc.keepalive_permit_without_calls': true,
    
    // Performance settings
    'grpc.max_send_message_length': 4 * 1024 * 1024,    // 4MB max send
    'grpc.max_receive_message_length': 4 * 1024 * 1024,  // 4MB max receive
    
    // Retry settings
    'grpc.max_connection_attempts': 5,
    'grpc.initial_reconnect_backoff_ms': 1000,
  }
);
```

---

## ğŸª Stubs: Your Service Proxies

A **Stub** (or client) is a generated class that provides methods for calling remote procedures. It's like having a local object that magically executes code on a remote server.

### Generated Stub Structure

Given this service definition:
```protobuf
service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  rpc CreateUser(CreateUserRequest) returns (User);
  rpc StreamUserEvents(UserEventsRequest) returns (stream UserEvent);
}
```

Node.js generates this stub:
```javascript
const userService = new UserServiceClient(
  'localhost:50051',
  grpc.credentials.createInsecure()
);

// Unary call
userService.getUser({ user_id: 123 }, (error, user) => {
  if (error) {
    console.error('Error:', error);
  } else {
    console.log('User:', user);
  }
});

// Promise-based call
const { promisify } = require('util');
const getUserAsync = promisify(userService.getUser.bind(userService));

try {
  const user = await getUserAsync({ user_id: 123 });
  console.log('User:', user);
} catch (error) {
  console.error('Error:', error);
}

// Streaming call
const stream = userService.streamUserEvents({ user_id: 123 });
stream.on('data', (event) => {
  console.log('Event:', event);
});
stream.on('error', (error) => {
  console.error('Stream error:', error);
});
stream.on('end', () => {
  console.log('Stream ended');
});
```

---

## ğŸ¯ Service Implementation Architecture

Here's how a complete gRPC service is structured:

### Server-Side Service Implementation

```javascript
const grpc = require('@grpc/grpc-js');
const protoLoader = require('@grpc/proto-loader');

// Load protobuf definition
const packageDefinition = protoLoader.loadSync('user.proto', {
  keepCase: true,
  longs: String,
  enums: String,
  defaults: true,
  oneofs: true
});

const userProto = grpc.loadPackageDefinition(packageDefinition).user;

// Implement service methods
const userService = {
  // Unary RPC implementation
  GetUser: (call, callback) => {
    const userId = call.request.user_id;
    
    // Business logic here
    const user = findUserById(userId);
    
    if (user) {
      callback(null, user);  // Success
    } else {
      callback({             // Error
        code: grpc.status.NOT_FOUND,
        details: 'User not found'
      });
    }
  },

  // Server streaming RPC implementation
  StreamUserEvents: (call) => {
    const userId = call.request.user_id;
    
    // Send multiple responses
    setInterval(() => {
      call.write({
        user_id: userId,
        event_type: 'ACTIVITY',
        message: 'User is active',
        timestamp: Date.now()
      });
    }, 1000);
    
    // End stream after 10 seconds
    setTimeout(() => {
      call.end();
    }, 10000);
  }
};

// Create and start server
const server = new grpc.Server();
server.addService(userProto.UserService.service, userService);

server.bindAsync('0.0.0.0:50051', 
  grpc.ServerCredentials.createInsecure(),
  (error, port) => {
    if (error) {
      console.error('Failed to start server:', error);
    } else {
      console.log(`Server running on port ${port}`);
      server.start();
    }
  }
);
```

---

## ğŸ”„ Request Lifecycle Deep Dive

Let's trace exactly what happens during a gRPC call:

### 1. Client-Side Journey
```
1. Application Code
   â†“
2. Generated Stub
   â†“
3. gRPC Client Library
   â†“
4. Protocol Buffers Serialization
   â†“
5. HTTP/2 Transport
   â†“
6. Network
```

### 2. Server-Side Journey
```
1. Network
   â†“
2. HTTP/2 Transport
   â†“
3. Protocol Buffers Deserialization
   â†“
4. gRPC Server Library
   â†“
5. Service Implementation
   â†“
6. Application Code
```

### 3. Complete Round Trip

```javascript
// Client sends request
const request = { user_id: 123 };

// 1. Stub method called
userClient.getUser(request, (error, response) => {
  // 8. Response received and callback executed
  console.log('User:', response);
});

// 2. Request serialized to binary
// 3. HTTP/2 stream created
// 4. Binary data sent over network
// 5. Server receives and deserializes
// 6. Service method executed
// 7. Response serialized and sent back
```

---

## âš¡ Performance Characteristics

### Why gRPC is Fast

**1. Binary Serialization**
```
JSON: {"id": 123, "name": "Alice"} = 28 bytes
Protobuf: [Binary representation] = 12 bytes (57% smaller!)
```

**2. HTTP/2 Multiplexing**
```
Traditional: 6 connections Ã— 100ms = 600ms total
gRPC: 1 connection Ã— 6 concurrent streams = 100ms total
```

**3. Connection Reuse**
```
REST: Create connection â†’ Request â†’ Close connection (repeated)
gRPC: Create connection â†’ Multiple requests â†’ Keep alive
```

### Benchmark: gRPC vs REST

| Metric | REST (JSON) | gRPC |
|--------|-------------|------|
| **Latency** | 100ms | 50ms (-50%) |
| **Throughput** | 1000 req/s | 2500 req/s (+150%) |
| **CPU Usage** | 80% | 45% (-44%) |
| **Network Bandwidth** | 1MB/s | 400KB/s (-60%) |

---

## ğŸ§  Knowledge Check

Test your architectural understanding:

**What are the four types of gRPC services?**
   <details><summary>Click for answer</summary>Unary (1â†’1), Server Streaming (1â†’many), Client Streaming (manyâ†’1), Bidirectional Streaming (manyâ†’many)</details>

**Why is HTTP/2 important for gRPC performance?**
   <details><summary>Click for answer</summary>Multiplexing (concurrent streams), header compression, binary protocol, and connection reuse eliminate HTTP/1.1 bottlenecks</details>

**What's the difference between a Channel and a Stub?**
   <details><summary>Click for answer</summary>Channel = connection to server; Stub = generated client code that uses the channel to make RPC calls</details>

**When would you use bidirectional streaming?**
   <details><summary>Click for answer</summary>Real-time applications like chat, live collaboration, gaming, or any scenario requiring full-duplex communication</details>

---

## ğŸ¨ Architectural Patterns

### 1. **Microservices with gRPC**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    gRPC    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gateway   â”‚ â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚ User Serviceâ”‚
â”‚             â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚    gRPC    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚ â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚Order Serviceâ”‚
â”‚             â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚    gRPC    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚ â”€â”€â”€â”€â”€â”€â”€â”€>  â”‚Pay Service  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. **Event-Driven Architecture**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  Stream   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Events    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Processor 1 â”‚
â”‚   Service   â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚  Stream   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚ â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Processor 2 â”‚
â”‚             â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚  Stream   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚ â”€â”€â”€â”€â”€â”€â”€â”€> â”‚ Processor 3 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. **Load Balancing Strategies**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Client    â”‚ â”€â”€â”€â”€â”€â”€â”€â”€> â”‚   Server 1  â”‚
â”‚             â”‚     â•²     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚      â•²    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   [Stub]    â”‚       â•²â”€â”€>â”‚   Server 2  â”‚
â”‚             â”‚       â•±   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚             â”‚      â•±    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚     â•±     â”‚   Server 3  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”€â”€â”€â”€â”€â”€â”€â”€> â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Key Takeaways

- **gRPC Architecture** = Client (Stub) + Channel + HTTP/2 + Server (Service)
- **HTTP/2** provides multiplexing, compression, and binary transport
- **Four service types** cover all communication patterns
- **Channels** manage connections with configuration options
- **Stubs** provide type-safe client interfaces
- **Performance benefits** come from binary serialization and connection reuse

---

## ğŸ¯ Practical Exercise: Design Your Architecture

Design the gRPC architecture for a **Social Media Platform**:

### Requirements:
1. **User posts** and timeline feeds
2. **Real-time messaging** between users
3. **File uploads** for photos/videos
4. **Live notifications** for likes/comments

### Your Challenge:
1. Define **4 services** (UserService, PostService, MessageService, MediaService)
2. Choose appropriate **RPC types** for each operation
3. Consider **performance implications**
4. Think about **scalability patterns**

<details>
<summary>ğŸ” Click to see suggested solution</summary>

```protobuf
// User Service - Unary RPCs for CRUD
service UserService {
  rpc GetUser(GetUserRequest) returns (User);
  rpc CreateUser(CreateUserRequest) returns (User);
  rpc FollowUser(FollowRequest) returns (FollowResponse);
}

// Post Service - Mixed RPC types
service PostService {
  rpc CreatePost(CreatePostRequest) returns (Post);           // Unary
  rpc GetUserFeed(FeedRequest) returns (stream Post);         // Server streaming
  rpc GetPostLikes(PostRequest) returns (stream Like);        // Server streaming
}

// Message Service - Bidirectional for real-time chat
service MessageService {
  rpc SendMessage(SendMessageRequest) returns (Message);      // Unary
  rpc LiveChat(stream ChatMessage) returns (stream ChatMessage); // Bidirectional
}

// Media Service - Client streaming for uploads
service MediaService {
  rpc UploadMedia(stream MediaChunk) returns (MediaResponse); // Client streaming
  rpc GetMedia(MediaRequest) returns (Media);                 // Unary
}

// Notification Service - Server streaming for real-time updates
service NotificationService {
  rpc StreamNotifications(NotificationRequest) returns (stream Notification);
}
```

**Architecture Benefits:**
- **Real-time features** use streaming RPCs
- **File uploads** use client streaming for efficiency
- **CRUD operations** use simple unary RPCs
- **Feeds** use server streaming for large data sets

</details>

---

## ğŸ† Module 1 Complete!

Congratulations! You've completed the **Foundation & Concepts** module. You now understand:

âœ… **What gRPC is** and when to use it  
âœ… **Protocol Buffers** for efficient data serialization  
âœ… **gRPC Architecture** and communication patterns  

---

Time to get your hands dirty with actual code! In Module 2, we'll:
- Set up your Node.js gRPC development environment
- Install and configure all necessary tools
- Create your first working gRPC project structure

---

## ğŸ“– Additional Resources

- [gRPC Core Concepts](https://grpc.io/docs/what-is-grpc/core-concepts/)
- [HTTP/2 Specification](https://tools.ietf.org/html/rfc7540)
- [gRPC Performance Best Practices](https://grpc.io/docs/guides/performance/)
- [Service Design Patterns](https://microservices.io/patterns/)

---

**ğŸ’¡ Pro Tip:** Keep your protobuf files and architectural diagrams in version control. They become valuable documentation for your team and future you!
